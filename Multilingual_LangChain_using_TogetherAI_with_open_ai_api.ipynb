{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bJTr-Sv18Jsp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade langchain langchain-openai langchain-core langchain_community docx2txt pypdf  langchain_chroma sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1d1pFueL4dJ"
   },
   "source": [
    "### What is Retrieval Augmented Generation (RAG)?\n",
    "RAG is a technique that enhances language models by combining them with a retrieval system. It allows the model to access and utilize external knowledge when generating responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTwMayJCNLAn"
   },
   "source": [
    "The process typically involves:\n",
    "#### Indexing a large corpus of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvZGjmr9Rl6w",
    "outputId": "b4f1bae5-87e8-43b6-b648-0473d8738bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.8\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynuxRM7_-Nhu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZLC1ePBkA0Dd"
   },
   "outputs": [],
   "source": [
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "#os.environ[\"LANGCHAIN_PROJECT\"] = \"Multilingual-RAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkGT7MDh-mGk"
   },
   "source": [
    "### Call LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFPaXjak-Dx6",
    "outputId": "f7fadda0-e604-462d-e61b-42e2d40ead86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abubakarsiddique/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 14, 'total_tokens': 32, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-Vision-Free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-96a72051-d219-4440-819a-6f9274c4ce14-0', usage_metadata={'input_tokens': 14, 'output_tokens': 18, 'total_tokens': 32, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    ")\n",
    "\n",
    "\n",
    "llm_response = llm.invoke(\"Tell me a joke\")\n",
    "\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nv-79m-P_kVF"
   },
   "source": [
    "### Parsing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "g1e1HTs1-vmG",
    "outputId": "b910f96b-8542-4a9f-9274-1a4f31ea1dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIWdUqOe_nIc"
   },
   "source": [
    "### Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dZAu9MKc_S5z",
    "outputId": "990ebf8f-c4b1-4d98-a542-c06e5f509c80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and Schr√∂dinger\\'s cat?\" The librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | output_parser\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1G41Ztxd541C",
    "outputId": "7fec3837-7f36-446e-bc50-f4f7537c5414"
   },
   "outputs": [],
   "source": [
    "#from typing import List\n",
    "#from pydantic import BaseModel, Field # type: ignore\n",
    "\n",
    "#class MobileReview(BaseModel):\n",
    "#    phone_model: str = Field(description=\"Name and model of the phone\")\n",
    "#    rating: float = Field(description=\"Overall rating out of 5\")\n",
    "#    pros: List[str] = Field(description=\"List of positive aspects\")\n",
    "#    cons: List[str] = Field(description=\"List of negative aspects\")\n",
    "#    summary: str = Field(description=\"Brief summary of the review\")\n",
    "\n",
    "#review_text = \"\"\"\n",
    "#Just got my hands on the new Galaxy S21 and wow, this thing is slick! The screen is gorgeous,\n",
    "#colors pop like crazy. Camera's insane too, especially at night - my Insta game's never been\n",
    "#stronger. Battery life's solid, lasts me all day no problem.\n",
    "\n",
    "#Not gonna lie though, it's pretty pricey. And what's with ditching the charger? C'mon Samsung.\n",
    "#Also, still getting used to the new button layout, keep hitting Bixby by mistake.\n",
    "\n",
    "#Overall, I'd say it's a solid 4 out of 5. Great phone, but a few annoying quirks keep it from\n",
    "#being perfect. If you're due for an upgrade, definitely worth checking out!\n",
    "#\"\"\"\n",
    "\n",
    "#structured_llm = llm.with_structured_output(MobileReview)\n",
    "#output = structured_llm.invoke(review_text)\n",
    "#output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB-1N7n7n9cz",
    "outputId": "ed375a70-2d1f-4ac5-8d07-ba44561c61be"
   },
   "outputs": [],
   "source": [
    "#output.pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpRopsnw_3yo"
   },
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH9TLudu_-Dw",
    "outputId": "0bd110f8-6b45-43ef-b5bb-2f7baa12c396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me a short joke about snake', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "prompt.invoke({\"topic\": \"snake\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RakPrAV0BqlL",
    "outputId": "9e8c870a-0b12-4532-cd7e-52bd8503d3f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the snake visit the doctor?\\n\\nBecause it had a hiss-terical pain!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"topic\": \"snake\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pizjNr0h8f_E",
    "outputId": "2ab1230f-7d5c-4ffb-c9d7-0c0f79bffe8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the lion go to the dentist?\n",
      "\n",
      "Because it had a ROAR-ing toothache!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    ")\n",
    "\n",
    "# Define the output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Compose the chain\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# Use the chain\n",
    "result = chain.invoke({\"topic\": \"Lion\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59Hl3OjvsA02"
   },
   "source": [
    "### LLM Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37riQcz1FoB_",
    "outputId": "3227525d-8f0b-469d-ac4b-3760895ce870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Cakes! The sweetest topic around!\\n\\nWhy did the cake go to therapy? Because it was feeling crumby!\\n\\nBut seriously, cakes are amazing creations that bring people together. From classic vanilla to decadent chocolate, there's a cake to suit every taste. And let's not forget the frosting ‚Äì the icing on the cake (get it?)!\\n\\nDid you know that cakes have been around since ancient Egypt? They were made with honey and nuts, and were often served at special occasions. Who knew our ancestors loved cake parties too?\\n\\nWhat's your favorite type of cake? Do you have a sweet tooth for something specific?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 29, 'total_tokens': 157, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-Vision-Free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b992f954-8132-4403-a3fb-9669111760c9-0', usage_metadata={'input_tokens': 29, 'output_tokens': 128, 'total_tokens': 157, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"You are a helpful assistant that tells jokes.\")\n",
    "human_message = HumanMessage(content=\"Tell me about Cakes\")\n",
    "llm.invoke([system_message, human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEufVkCLMm68",
    "outputId": "f8f21040-feae-4a1c-a4c3-297c87d2c9ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that tells jokes.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about Cakes', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that tells jokes.\"),\n",
    "    (\"human\", \"Tell me about {topic}\")\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"topic\": \"Cakes\"\n",
    "    }\n",
    ")\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY86l3k_HwTb",
    "outputId": "995734c5-18f8-4beb-872b-ae9702bd6044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Cakes! They're the icing on the cake (get it?)! But seriously, cakes are a sweet treat that brings people together. Did you hear about the cake that went to therapy? It was feeling crumby!\\n\\nBut let's get serious for a sec. Cakes have a rich history, with ancient Egyptians and Greeks baking cakes for special occasions. And today, we have all sorts of delicious cakes, from classic vanilla and chocolate to creative flavors like red velvet and carrot cake.\\n\\nSome fun facts about cakes:\\n\\n* The world's largest cake was over 2,000 pounds and had 2,000 candles!\\n* The average American eats around 19 pounds of cake per year. That's a lot of frosting!\\n* Cakes can be used for more than just dessert ‚Äì they can be used as a base for science experiments, like making a volcano erupt!\\n\\nOkay, okay, I'll stop with the cake puns now. But before I go, here's one more: Why did the cake go to the party? Because it was a batter guest!\\n\\nHope that made you laugh and satisfied your cake cravings!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 228, 'prompt_tokens': 29, 'total_tokens': 257, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-Vision-Free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e95d8ca7-5011-45e5-8400-dc763869314a-0', usage_metadata={'input_tokens': 29, 'output_tokens': 228, 'total_tokens': 257, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-G_ZBmiSJRP",
    "outputId": "d8563a20-61c0-46e4-a84f-43751ef9c115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Split the documents into 5 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docx_loader = Docx2txtLoader(\"./docs/NextView_Technologies_Profile_Urdu.docx\")\n",
    "documents = docx_loader.load()\n",
    "\n",
    "print(len(documents))\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split the documents into {len(splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaYyDYxKypL7",
    "outputId": "e5a3fbde-0e65-406c-9d0f-231cad1d8732"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\nŸÇ€åÿßŸÖ: 2010\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ\\n\\n€ÅŸÖÿßÿ±€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫:\\nŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€å €Å€í ÿ¨Ÿà ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î \\n€ÅŸÖÿßÿ±€å Ÿπ€åŸÖ ⁄©ÿß ŸÖŸÇÿµÿØ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß €Å€í€î\\n\\nÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™:\\n1. Ÿà€åÿ® ÿßŸàÿ± ŸÖŸàÿ®ÿßÿ¶ŸÑ ÿß€åŸæŸÑ€å⁄©€åÿ¥ŸÜ ⁄àŸà€åŸÑŸæŸÖŸÜŸπ\\n2. ⁄à€åÿ¨€åŸπŸÑ ŸÖÿßÿ±⁄©€åŸπŸÜ⁄Ø ÿßŸàÿ± ÿ®ÿ±ÿßŸÜ⁄àŸÜ⁄Ø\\n3. ÿß€å ⁄©ÿßŸÖÿ±ÿ≥ ÿ≥ŸÑŸàÿ¥ŸÜÿ≤\\n4. ⁄©ŸÑÿßÿ§⁄à ÿ®€åÿ≥⁄à ÿß€åŸæŸÑ€å⁄©€åÿ¥ŸÜÿ≤\\n5. ÿ¢ÿ±Ÿπ€åŸÅ€åÿ¥ŸÑ ÿßŸÜŸπ€åŸÑ€åÿ¨ŸÜÿ≥ Ÿæÿ± ŸÖÿ®ŸÜ€å Ÿæÿ±ÿß⁄à⁄©Ÿπÿ≥\\n\\nÿß€ÅŸÖ ⁄©ŸÑÿßÿ¶ŸÜŸπÿ≥:\\n1. ŸÖÿπÿ±ŸàŸÅ ÿ±€åŸπ€åŸÑ ÿßÿ≥ŸπŸàÿ±ÿ≤ ŸÜ€åŸπ Ÿàÿ±⁄©\\n2. ÿ™ÿπŸÑ€åŸÖ€å ÿßÿØÿßÿ±€í ÿßŸàÿ± €åŸàŸÜ€åŸàÿ±ÿ≥Ÿπ€åÿ≤\\n3. ŸÅ€åÿ¥ŸÜ ÿßŸàÿ± Ÿπ€å⁄©ÿ≥Ÿπÿßÿ¶ŸÑ ÿßŸÜ⁄àÿ≥Ÿπÿ±€å\\n4. ÿµÿ≠ÿ™ ⁄©€í ÿ¥ÿπÿ®€í ŸÖ€å⁄∫ ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ™ŸÜÿ∏€åŸÖ€å⁄∫\\n\\nÿß€åŸàÿßÿ±⁄àÿ≤ ÿßŸàÿ± ÿßÿπÿ≤ÿßÿ≤ÿßÿ™:\\n- ÿ®€Åÿ™ÿ±€åŸÜ ⁄à€åÿ¨€åŸπŸÑ ÿ≥ÿ±Ÿàÿ≥ÿ≤ ⁄©ŸÖŸæŸÜ€å 2021\\n- ÿ¢ÿ¶€å Ÿπ€å ÿßŸÜŸàŸà€åÿ¥ŸÜ ÿß€åŸàÿßÿ±⁄à 2020\\n- Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ŸπÿßŸæ 100 Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€åÿ≤ ŸÖ€å⁄∫ ÿ¥ÿßŸÖŸÑ\\n\\nÿ±ÿßÿ®ÿ∑€í ⁄©€å ŸÖÿπŸÑŸàŸÖÿßÿ™:\\nŸà€åÿ® ÿ≥ÿßÿ¶Ÿπ: www.nextviewtech.com\\nÿß€å ŸÖ€åŸÑ: info@nextviewtech.com\\nŸÅŸàŸÜ: +92 (42) 34567890\\nŸæÿ™€Å: 456 ⁄à€åÿ¨€åŸπŸÑ ŸπÿßŸàÿ±ÿå ŸÖ€åŸÜ ÿ®ŸÑ€åŸàÿßÿ±⁄àÿå ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RC5yK58oTa9-",
    "outputId": "27b792fe-6555-480f-df5d-54fd17250a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='€ÅŸÖÿßÿ±€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫:\\nŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€å €Å€í ÿ¨Ÿà ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î \\n€ÅŸÖÿßÿ±€å Ÿπ€åŸÖ ⁄©ÿß ŸÖŸÇÿµÿØ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß €Å€í€î')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVILJLkITgfz",
    "outputId": "9dce62d3-5976-4919-b149-80ee8beb5f9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './docs/NextView_Technologies_Profile_Urdu.docx'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "LAPIDXucTjFN",
    "outputId": "49523e2f-c352-44e0-d293-f725dac47a59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\nŸÇ€åÿßŸÖ: 2010\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHPIWFXyTsGM",
    "outputId": "f0ced858-670e-449d-c62a-a7103838efb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file type: .DS_Store\n",
      "Loaded 2 documents from the folder.\n",
      "Split the documents into 12 chunks.\n"
     ]
    }
   ],
   "source": [
    "# 1. Function to load documents from a folder\n",
    "\n",
    "def load_documents(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif filename.endswith('.txt'):\n",
    "            loader = TextLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {filename}\")\n",
    "            continue\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "# Load documents from a folder\n",
    "folder_path = \"./docs\"\n",
    "documents = load_documents(folder_path)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Split the documents into {len(splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRD0I2D4NSkU",
    "outputId": "0d243630-4507-4d17-9300-8244b932f225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings for 12 document chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "embeddings = JinaEmbeddings(\n",
    "    jina_api_key=\"\", model_name=\"jina-embeddings-v3\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 4. Embedding Documents\n",
    "\n",
    "document_embeddings = embeddings.embed_documents([split.page_content for split in splits])\n",
    "\n",
    "print(f\"Created embeddings for {len(document_embeddings)} document chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UKzaMunIUkKZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.039562646,\n",
       " -0.1678835,\n",
       " -0.033479914,\n",
       " 0.07796331,\n",
       " 0.020988848,\n",
       " 0.033447348,\n",
       " -0.073860295,\n",
       " 0.06723421,\n",
       " -0.03621315,\n",
       " 0.0048393896,\n",
       " 0.064838976,\n",
       " 0.10490065,\n",
       " 0.06885033,\n",
       " 0.025702339,\n",
       " -0.019857733,\n",
       " -0.095474094,\n",
       " -0.16654961,\n",
       " 0.0942608,\n",
       " 0.038274907,\n",
       " 0.05775096,\n",
       " -0.106425114,\n",
       " -0.022127878,\n",
       " 0.035077944,\n",
       " 0.13666102,\n",
       " -0.015386192,\n",
       " 0.115907155,\n",
       " 0.059515428,\n",
       " 0.005777327,\n",
       " -0.02542826,\n",
       " 0.04835877,\n",
       " 0.07165442,\n",
       " 0.039955247,\n",
       " -0.05186961,\n",
       " -0.0011829938,\n",
       " 0.048365403,\n",
       " 0.022405121,\n",
       " -0.054259714,\n",
       " 0.09549338,\n",
       " -0.035215132,\n",
       " 0.038746472,\n",
       " 0.051126674,\n",
       " 0.09054131,\n",
       " 0.022253497,\n",
       " 0.0047408035,\n",
       " -0.016624816,\n",
       " -0.017458316,\n",
       " 0.043613832,\n",
       " -0.020425977,\n",
       " -0.03665984,\n",
       " -0.010318311,\n",
       " 0.000610106,\n",
       " -0.022059584,\n",
       " -0.028088525,\n",
       " -0.0230158,\n",
       " 0.06504521,\n",
       " 0.033805702,\n",
       " -0.027268255,\n",
       " -0.05539944,\n",
       " 0.039920423,\n",
       " -0.004556493,\n",
       " -0.006776171,\n",
       " 0.022336846,\n",
       " -0.034616493,\n",
       " 0.005975196,\n",
       " 0.041322917,\n",
       " 0.08851151,\n",
       " 0.042197313,\n",
       " -0.041517396,\n",
       " 0.019787066,\n",
       " -0.019470876,\n",
       " -0.029995305,\n",
       " 0.020206323,\n",
       " -0.040054597,\n",
       " 0.049126428,\n",
       " -0.059306774,\n",
       " 0.02870045,\n",
       " -0.0048271026,\n",
       " -0.066995405,\n",
       " -0.081647225,\n",
       " -0.04879476,\n",
       " 0.13498943,\n",
       " 0.038070478,\n",
       " 0.02182606,\n",
       " 0.026576428,\n",
       " 0.027303983,\n",
       " 0.03438589,\n",
       " 0.023208808,\n",
       " 0.009818635,\n",
       " 0.032589238,\n",
       " 0.0014424073,\n",
       " -0.007890042,\n",
       " -0.035620406,\n",
       " 0.0062856437,\n",
       " 0.018204566,\n",
       " -0.05615052,\n",
       " -0.059696335,\n",
       " -0.047714185,\n",
       " -0.061704118,\n",
       " -0.058092277,\n",
       " 0.032102592,\n",
       " -0.056267504,\n",
       " 0.020497926,\n",
       " 0.01291965,\n",
       " -0.057236575,\n",
       " -0.011899329,\n",
       " 0.00983029,\n",
       " -0.06980794,\n",
       " -0.032867536,\n",
       " -0.056016646,\n",
       " 0.03320644,\n",
       " -0.030980391,\n",
       " -0.054611586,\n",
       " -0.015970565,\n",
       " 0.025563864,\n",
       " -0.016352322,\n",
       " -0.0250087,\n",
       " 0.06149035,\n",
       " -0.015808577,\n",
       " 0.024163479,\n",
       " -0.0033662913,\n",
       " -0.03758383,\n",
       " 0.012984664,\n",
       " -0.021575239,\n",
       " 0.001878664,\n",
       " 0.08608854,\n",
       " 0.018791558,\n",
       " -0.001258568,\n",
       " 0.07709555,\n",
       " -0.036712907,\n",
       " 0.029885555,\n",
       " -0.03188038,\n",
       " -0.00936224,\n",
       " 0.004508854,\n",
       " 0.025901185,\n",
       " -0.0149409305,\n",
       " 0.0199679,\n",
       " 0.06806277,\n",
       " 0.028283605,\n",
       " -0.03689457,\n",
       " 0.019439269,\n",
       " 9.874613e-06,\n",
       " 0.003093595,\n",
       " -0.05360814,\n",
       " -0.001750294,\n",
       " 0.015363287,\n",
       " 0.054872245,\n",
       " -0.046769183,\n",
       " -0.043845695,\n",
       " 0.06951607,\n",
       " -0.023397142,\n",
       " 0.07298228,\n",
       " 0.0147556495,\n",
       " -0.027344614,\n",
       " -0.016776063,\n",
       " 0.09105871,\n",
       " 0.0530419,\n",
       " -0.018920964,\n",
       " -0.029575747,\n",
       " 0.01329138,\n",
       " 0.02332248,\n",
       " -0.032338075,\n",
       " -0.0020516582,\n",
       " -0.0061783423,\n",
       " -0.004528603,\n",
       " -0.0037549913,\n",
       " -0.009228769,\n",
       " 0.03950192,\n",
       " -0.010374072,\n",
       " -0.018510452,\n",
       " -0.043157037,\n",
       " 0.04137207,\n",
       " 0.067178726,\n",
       " 0.016320135,\n",
       " -0.0056560617,\n",
       " -0.01905367,\n",
       " -0.031575546,\n",
       " 0.0109354,\n",
       " 0.10194339,\n",
       " -0.00011442491,\n",
       " 0.052619174,\n",
       " -0.013011122,\n",
       " -0.03400048,\n",
       " 0.019139186,\n",
       " 0.025976414,\n",
       " 0.022782616,\n",
       " -0.032373957,\n",
       " 0.055700656,\n",
       " 0.05901129,\n",
       " 0.047321558,\n",
       " 0.024967922,\n",
       " -0.05387107,\n",
       " 0.053422112,\n",
       " -0.04096472,\n",
       " -0.05892446,\n",
       " 0.008931948,\n",
       " -0.013031029,\n",
       " 0.014128385,\n",
       " -0.03154072,\n",
       " 0.038722657,\n",
       " 0.027477806,\n",
       " -0.00052757334,\n",
       " -0.059572715,\n",
       " 0.03515272,\n",
       " -0.044596165,\n",
       " -0.013265299,\n",
       " -0.0008832879,\n",
       " 0.019809812,\n",
       " 0.024784015,\n",
       " -0.024623893,\n",
       " 0.044522822,\n",
       " -0.06867545,\n",
       " 0.01912283,\n",
       " 0.016239969,\n",
       " 0.027362628,\n",
       " -0.04848179,\n",
       " 0.022169186,\n",
       " 0.022941064,\n",
       " 0.017016295,\n",
       " 0.024314161,\n",
       " 0.018612063,\n",
       " -0.014932726,\n",
       " 0.06344115,\n",
       " 0.021826778,\n",
       " 0.03678301,\n",
       " 0.0016864507,\n",
       " 0.010565685,\n",
       " -0.04634043,\n",
       " -0.024272704,\n",
       " 0.06599317,\n",
       " -0.034756605,\n",
       " -0.021485953,\n",
       " 0.062437706,\n",
       " -0.015485579,\n",
       " 0.004118665,\n",
       " -0.01808509,\n",
       " 0.017455226,\n",
       " -0.0026533313,\n",
       " -0.026365593,\n",
       " 0.0005064697,\n",
       " 0.0021565855,\n",
       " 0.00017058206,\n",
       " 0.017161729,\n",
       " 0.013458381,\n",
       " 0.046626113,\n",
       " 0.061433062,\n",
       " -0.02932485,\n",
       " 0.037337195,\n",
       " -0.025435686,\n",
       " -0.0029275778,\n",
       " 0.02835974,\n",
       " 0.029383834,\n",
       " -0.043318648,\n",
       " -0.011671868,\n",
       " 0.034910604,\n",
       " -0.024817316,\n",
       " -0.0055179563,\n",
       " 0.042822354,\n",
       " -0.016121851,\n",
       " 0.02644007,\n",
       " 0.017915564,\n",
       " 0.008417768,\n",
       " -0.020267313,\n",
       " 0.061332956,\n",
       " 0.041082613,\n",
       " -0.009518901,\n",
       " 0.023847418,\n",
       " 0.020834671,\n",
       " 0.035258852,\n",
       " -0.002180631,\n",
       " 0.033188954,\n",
       " -0.027415657,\n",
       " -0.024757689,\n",
       " -0.02028532,\n",
       " 0.0027142842,\n",
       " -0.01704984,\n",
       " 0.005240103,\n",
       " -0.027269762,\n",
       " 0.0007992689,\n",
       " 0.016475528,\n",
       " -0.04666486,\n",
       " -0.007722164,\n",
       " -0.042966478,\n",
       " -0.020992674,\n",
       " 0.0141781345,\n",
       " 0.01030152,\n",
       " -0.0031904045,\n",
       " -0.012613951,\n",
       " 0.04443747,\n",
       " 0.011005294,\n",
       " -0.033297498,\n",
       " 0.0170813,\n",
       " 0.007594953,\n",
       " -0.0110754715,\n",
       " 0.010543825,\n",
       " 0.008602498,\n",
       " 0.07761114,\n",
       " -0.00032729443,\n",
       " 0.002435044,\n",
       " -0.01781154,\n",
       " -0.02761002,\n",
       " -0.023652337,\n",
       " 0.06539617,\n",
       " -0.020190023,\n",
       " 0.015558396,\n",
       " 0.00025952424,\n",
       " -0.034237016,\n",
       " 0.003418708,\n",
       " -0.050790787,\n",
       " 0.025544265,\n",
       " 0.018530728,\n",
       " 0.020344982,\n",
       " 0.0016614979,\n",
       " -0.031610824,\n",
       " 0.014226868,\n",
       " 0.005652043,\n",
       " -0.016254894,\n",
       " -0.009684631,\n",
       " -0.018193861,\n",
       " 0.0018276703,\n",
       " -0.0067243287,\n",
       " 0.033844296,\n",
       " 0.029481525,\n",
       " -0.021576708,\n",
       " -0.014935239,\n",
       " -0.01772365,\n",
       " 0.023454694,\n",
       " 0.033131666,\n",
       " -0.0266901,\n",
       " -0.031364787,\n",
       " -0.0109848855,\n",
       " -0.0053221667,\n",
       " 0.04022872,\n",
       " 0.019787066,\n",
       " 0.07803688,\n",
       " 0.0005918196,\n",
       " -0.022664424,\n",
       " -0.027234634,\n",
       " 0.044082385,\n",
       " -0.002059309,\n",
       " 0.02697081,\n",
       " -0.0012046652,\n",
       " 0.038708482,\n",
       " 0.02241213,\n",
       " 0.0315466,\n",
       " 0.027235238,\n",
       " 0.015585079,\n",
       " -0.00039355704,\n",
       " -0.023218457,\n",
       " -0.021938676,\n",
       " -0.0030987489,\n",
       " -0.06484816,\n",
       " 0.03876155,\n",
       " -0.042752404,\n",
       " 0.002573524,\n",
       " 0.024464786,\n",
       " 0.054595303,\n",
       " -0.026095511,\n",
       " -0.0317652,\n",
       " 0.015610483,\n",
       " -0.023978576,\n",
       " 0.021389421,\n",
       " 0.034487877,\n",
       " -0.015050569,\n",
       " 0.012649398,\n",
       " -0.009295422,\n",
       " -0.015828712,\n",
       " -0.013431585,\n",
       " 0.024914553,\n",
       " -0.015687104,\n",
       " -0.045763932,\n",
       " 0.009511213,\n",
       " -0.0557091,\n",
       " -0.009555234,\n",
       " 0.03843697,\n",
       " 0.016269293,\n",
       " -0.01832487,\n",
       " 0.014415013,\n",
       " 0.008545423,\n",
       " 0.05333015,\n",
       " 0.012196353,\n",
       " -0.015718576,\n",
       " -0.021319818,\n",
       " -0.014674429,\n",
       " -0.026157925,\n",
       " 0.017702391,\n",
       " 0.022424268,\n",
       " 0.08121244,\n",
       " -0.002890369,\n",
       " 0.02768736,\n",
       " -0.029989125,\n",
       " 0.010007354,\n",
       " 0.000599798,\n",
       " 0.04787092,\n",
       " 0.0018114592,\n",
       " -0.0043344465,\n",
       " 0.0010711128,\n",
       " 0.017546415,\n",
       " -0.012713438,\n",
       " 0.026171193,\n",
       " 0.041777905,\n",
       " -0.002031664,\n",
       " 0.00252971,\n",
       " 0.027776457,\n",
       " -0.0012025922,\n",
       " 0.048818883,\n",
       " -0.003261873,\n",
       " -0.01844849,\n",
       " -0.019051973,\n",
       " 0.046333496,\n",
       " 0.012714168,\n",
       " -0.0040884856,\n",
       " -0.029467955,\n",
       " 0.0034322948,\n",
       " -0.032037765,\n",
       " 0.001462498,\n",
       " -0.034126513,\n",
       " 0.001826304,\n",
       " 0.030088173,\n",
       " -0.038987987,\n",
       " -0.04799158,\n",
       " -0.046244547,\n",
       " -0.015776653,\n",
       " 0.0380346,\n",
       " -0.0026651656,\n",
       " -0.0010984648,\n",
       " 0.030107167,\n",
       " -0.0050818827,\n",
       " -0.028964229,\n",
       " 0.02842125,\n",
       " -0.008036776,\n",
       " 0.0020489823,\n",
       " -0.041539107,\n",
       " -0.012838278,\n",
       " -0.025087398,\n",
       " -0.054158106,\n",
       " 0.027592836,\n",
       " -0.027852966,\n",
       " 0.012913884,\n",
       " 0.015305161,\n",
       " 0.008574085,\n",
       " 0.04249189,\n",
       " 0.0026320743,\n",
       " -0.06812066,\n",
       " 0.00839719,\n",
       " 0.00069485995,\n",
       " -0.021364527,\n",
       " 0.022197075,\n",
       " 0.05337869,\n",
       " -0.043835443,\n",
       " -0.027422028,\n",
       " -0.02125552,\n",
       " -0.011760438,\n",
       " 0.008196456,\n",
       " 0.0072581703,\n",
       " 0.025660727,\n",
       " -0.03283678,\n",
       " 0.03976831,\n",
       " 0.010677284,\n",
       " -0.06853313,\n",
       " 0.030119227,\n",
       " -0.015932763,\n",
       " -0.007884426,\n",
       " -0.026211444,\n",
       " 0.0030152432,\n",
       " 0.015673349,\n",
       " 0.02395581,\n",
       " -0.018651,\n",
       " -0.0012734388,\n",
       " 0.07709616,\n",
       " 0.0033410678,\n",
       " -0.00036347623,\n",
       " -0.028161792,\n",
       " -0.02366274,\n",
       " 0.021741938,\n",
       " 0.01384677,\n",
       " -0.01718456,\n",
       " -0.055438943,\n",
       " -0.0020105296,\n",
       " -0.01278256,\n",
       " 0.0038025174,\n",
       " 0.020075165,\n",
       " -0.0040871855,\n",
       " 0.08728736,\n",
       " 0.04576936,\n",
       " -0.013637369,\n",
       " 0.015847152,\n",
       " -0.026633715,\n",
       " 0.04726849,\n",
       " -0.0013495266,\n",
       " 0.013165008,\n",
       " 0.038555916,\n",
       " 0.0073460615,\n",
       " -0.013124528,\n",
       " 0.06543718,\n",
       " -0.02932519,\n",
       " 0.015193515,\n",
       " 0.010470745,\n",
       " -0.031760372,\n",
       " -0.0014656263,\n",
       " 0.009257069,\n",
       " 0.0030030885,\n",
       " -0.029045835,\n",
       " 0.021774879,\n",
       " -0.028542005,\n",
       " -0.02132645,\n",
       " -0.014045808,\n",
       " 0.067534514,\n",
       " -0.07515802,\n",
       " -0.073652856,\n",
       " 0.015251076,\n",
       " 0.0038958269,\n",
       " -0.008580662,\n",
       " 0.026571754,\n",
       " -0.010779103,\n",
       " 0.05757608,\n",
       " -0.019625228,\n",
       " 0.0019465801,\n",
       " -0.029412175,\n",
       " -0.006728079,\n",
       " -0.03321639,\n",
       " -0.027413508,\n",
       " -0.009122842,\n",
       " 0.010952901,\n",
       " -0.0100529585,\n",
       " 0.015443142,\n",
       " -0.008904593,\n",
       " -0.012718201,\n",
       " -0.017892838,\n",
       " 0.058268357,\n",
       " 0.008738053,\n",
       " -0.008168812,\n",
       " -0.032785676,\n",
       " 0.0197389,\n",
       " -0.010092006,\n",
       " -0.035953242,\n",
       " -0.02716227,\n",
       " -0.026673816,\n",
       " 0.0034769191,\n",
       " 0.0059350007,\n",
       " -0.00019566197,\n",
       " -0.001962372,\n",
       " 0.0065112896,\n",
       " -0.02419235,\n",
       " 0.017931242,\n",
       " 0.033735294,\n",
       " 0.020368727,\n",
       " -0.0028840655,\n",
       " 0.011092432,\n",
       " 0.06736567,\n",
       " 0.0410505,\n",
       " -0.035079148,\n",
       " -0.019243887,\n",
       " -0.028332751,\n",
       " 0.007045141,\n",
       " 0.01223344,\n",
       " 0.035711724,\n",
       " -0.02225776,\n",
       " -0.004830495,\n",
       " -0.0031428877,\n",
       " -0.005602637,\n",
       " 0.0038396413,\n",
       " 0.02736308,\n",
       " -0.06177558,\n",
       " -0.025015788,\n",
       " -0.0028450475,\n",
       " 0.0032421146,\n",
       " -0.025015185,\n",
       " 0.01766229,\n",
       " -0.045060497,\n",
       " 0.032193955,\n",
       " 0.016022258,\n",
       " 0.0014223212,\n",
       " 0.005290833,\n",
       " -0.031943094,\n",
       " -0.006605513,\n",
       " -0.00891591,\n",
       " -0.016037276,\n",
       " 0.046612397,\n",
       " 0.012256161,\n",
       " -0.04532493,\n",
       " 0.0040251957,\n",
       " -0.0057943254,\n",
       " -0.007910545,\n",
       " -0.0070858593,\n",
       " 0.0017835362,\n",
       " 0.036790848,\n",
       " 0.013477717,\n",
       " 0.008434201,\n",
       " -0.025918221,\n",
       " -0.011637533,\n",
       " 0.0022829105,\n",
       " 0.010051301,\n",
       " -0.013635107,\n",
       " 0.008144389,\n",
       " -0.051347386,\n",
       " 0.042588376,\n",
       " 0.015042994,\n",
       " 0.008461125,\n",
       " -0.003839387,\n",
       " -0.018819354,\n",
       " -0.0029121065,\n",
       " -0.0071351896,\n",
       " -0.017288715,\n",
       " 0.015506573,\n",
       " -0.0063608973,\n",
       " -0.028979804,\n",
       " 0.018635277,\n",
       " -0.008166135,\n",
       " 0.0010245948,\n",
       " -0.0046548625,\n",
       " -0.0010734943,\n",
       " 0.0049370425,\n",
       " -0.01677674,\n",
       " -0.026400344,\n",
       " 0.002637803,\n",
       " 0.011319246,\n",
       " 0.020861892,\n",
       " -0.022853248,\n",
       " -0.0040038447,\n",
       " -0.008085348,\n",
       " 0.02283169,\n",
       " -0.016567584,\n",
       " 0.028064707,\n",
       " -0.0065995585,\n",
       " -0.033381015,\n",
       " 0.006733827,\n",
       " 0.014192872,\n",
       " 0.017105358,\n",
       " 0.036289126,\n",
       " 0.022073152,\n",
       " -0.013154266,\n",
       " 0.015001987,\n",
       " -0.020001547,\n",
       " -0.017068986,\n",
       " -0.017595807,\n",
       " 0.018313374,\n",
       " -0.021750681,\n",
       " -0.015634906,\n",
       " 0.020695908,\n",
       " 0.004965819,\n",
       " -0.015132958,\n",
       " 0.063402556,\n",
       " -0.004224073,\n",
       " -0.019233711,\n",
       " 0.01655396,\n",
       " -0.007548388,\n",
       " 0.046720337,\n",
       " 0.00057301024,\n",
       " -0.037843738,\n",
       " 0.009153371,\n",
       " -0.021343939,\n",
       " 0.023845157,\n",
       " 0.020243209,\n",
       " -0.011727384,\n",
       " 0.043051053,\n",
       " -0.0124678295,\n",
       " -0.017392585,\n",
       " 0.033403028,\n",
       " -0.0010670989,\n",
       " 0.02101604,\n",
       " -0.0041963523,\n",
       " 0.01826844,\n",
       " 0.04786911,\n",
       " -0.030111313,\n",
       " 0.0026797892,\n",
       " 0.0070526595,\n",
       " -0.002742652,\n",
       " -0.019680481,\n",
       " -0.02539449,\n",
       " -0.0137334,\n",
       " -0.03028838,\n",
       " -0.00515745,\n",
       " -0.007543677,\n",
       " -0.0058597913,\n",
       " 0.032074403,\n",
       " -0.008392931,\n",
       " -0.01356704,\n",
       " -0.005147943,\n",
       " 0.009167749,\n",
       " -0.0012899938,\n",
       " -0.0003316664,\n",
       " 0.009599744,\n",
       " 0.020864831,\n",
       " -0.006490787,\n",
       " -0.02022513,\n",
       " -0.0004411493,\n",
       " 0.016168736,\n",
       " -0.021154286,\n",
       " 0.0044215275,\n",
       " -0.019360725,\n",
       " 0.0059613455,\n",
       " 0.014952659,\n",
       " 0.0034857383,\n",
       " 0.03139976,\n",
       " -0.042245552,\n",
       " -0.05169654,\n",
       " 0.001734766,\n",
       " -0.05992428,\n",
       " -0.011551036,\n",
       " 0.01930615,\n",
       " 0.0054107667,\n",
       " -0.025604298,\n",
       " 0.022519998,\n",
       " 0.015856065,\n",
       " 0.021715216,\n",
       " 0.004438252,\n",
       " -0.03155851,\n",
       " 0.0019745834,\n",
       " 0.00046294785,\n",
       " -0.016432563,\n",
       " -0.020060088,\n",
       " -0.023033176,\n",
       " 0.009880502,\n",
       " -0.022582034,\n",
       " -0.013448468,\n",
       " -0.021773333,\n",
       " 0.006600689,\n",
       " 0.0030349737,\n",
       " -0.0057034185,\n",
       " -0.022172501,\n",
       " 0.06608483,\n",
       " 0.0067798644,\n",
       " 0.012830402,\n",
       " 0.002739932,\n",
       " -0.0024067862,\n",
       " 0.034696225,\n",
       " 0.041180905,\n",
       " 0.03656524,\n",
       " 0.006244788,\n",
       " -0.0038994732,\n",
       " 0.03641094,\n",
       " -0.08997928,\n",
       " -0.013241216,\n",
       " -0.0031741206,\n",
       " -0.009100615,\n",
       " 0.013981548,\n",
       " 0.07007448,\n",
       " 0.02394963,\n",
       " -0.03778464,\n",
       " -0.012596817,\n",
       " 0.013612494,\n",
       " 0.052704804,\n",
       " -0.03968087,\n",
       " 0.013347613,\n",
       " 0.002814114,\n",
       " 0.008905997,\n",
       " 0.0030716266,\n",
       " -0.038153995,\n",
       " 0.052766915,\n",
       " 0.011468769,\n",
       " -0.034884673,\n",
       " -0.022573875,\n",
       " -0.008901587,\n",
       " 0.03344554,\n",
       " 0.05030173,\n",
       " -0.013780212,\n",
       " -0.029221617,\n",
       " -0.041674487,\n",
       " -0.02846768,\n",
       " -0.029811986,\n",
       " -0.008438874,\n",
       " 0.019388802,\n",
       " -0.03478035,\n",
       " 0.021653444,\n",
       " 0.011115045,\n",
       " -0.026621958,\n",
       " -0.022024006,\n",
       " -0.019749528,\n",
       " -0.041302115,\n",
       " 0.00027605103,\n",
       " 0.008093942,\n",
       " -0.026293004,\n",
       " -0.011727799,\n",
       " -0.0092577515,\n",
       " -0.00073464104,\n",
       " 0.012397237,\n",
       " -0.0022419896,\n",
       " -0.006791105,\n",
       " 0.0023168123,\n",
       " 0.0071373098,\n",
       " -0.022919655,\n",
       " -0.01634271,\n",
       " 0.015386721,\n",
       " 0.003743647,\n",
       " -0.0039677643,\n",
       " -0.0026407808,\n",
       " 0.059809703,\n",
       " -0.005624798,\n",
       " -0.013177407,\n",
       " 0.0041712704,\n",
       " -0.019037576,\n",
       " -0.015052001,\n",
       " -0.020668922,\n",
       " -0.02180631,\n",
       " 0.004667658,\n",
       " -0.02790068,\n",
       " -0.031770326,\n",
       " -0.018880336,\n",
       " 0.00042552705,\n",
       " 0.011367414,\n",
       " -0.01698343,\n",
       " 0.0011404565,\n",
       " -0.011406384,\n",
       " -0.027780076,\n",
       " 0.012980028,\n",
       " -0.00038575064,\n",
       " 0.014500304,\n",
       " 0.0070816055,\n",
       " 0.009244654,\n",
       " -0.062904455,\n",
       " -0.020582765,\n",
       " -0.03269085,\n",
       " -0.0061252187,\n",
       " 0.017769555,\n",
       " -0.02888332,\n",
       " 0.0021726128,\n",
       " 0.0102095585,\n",
       " -0.014865588,\n",
       " -0.022828298,\n",
       " 0.029469464,\n",
       " -0.011342989,\n",
       " -0.0048451186,\n",
       " 0.00093083305,\n",
       " -0.005459078,\n",
       " -0.024617486,\n",
       " -0.022716133,\n",
       " -0.02041241,\n",
       " 0.0016549919,\n",
       " -0.013059326,\n",
       " 0.014438739,\n",
       " 0.019326974,\n",
       " 0.017120808,\n",
       " -0.022099385,\n",
       " 0.019464577,\n",
       " -3.3166638e-05,\n",
       " -0.0010056181,\n",
       " -0.023461554,\n",
       " 0.044986628,\n",
       " -0.025222061,\n",
       " 0.0075486517,\n",
       " -0.031297248,\n",
       " -0.0028068023,\n",
       " -0.026091592,\n",
       " -0.006039618,\n",
       " -0.012640862,\n",
       " 0.013159957,\n",
       " -0.015902348,\n",
       " 0.011307506,\n",
       " -0.023046292,\n",
       " -0.01954691,\n",
       " -0.00051855383,\n",
       " 0.025915356,\n",
       " -0.0034518559,\n",
       " -0.012165871,\n",
       " 0.0014078013,\n",
       " -0.043386485,\n",
       " 0.0065930947,\n",
       " -0.031097382,\n",
       " -0.011677974,\n",
       " -0.008088269,\n",
       " 0.008105286,\n",
       " -0.0075952173,\n",
       " -0.0048038275,\n",
       " -0.0101803485,\n",
       " -0.009832405,\n",
       " 0.032152947,\n",
       " -0.014821267,\n",
       " 0.028277801,\n",
       " -0.06103144,\n",
       " 0.0013834634,\n",
       " -0.0036516094,\n",
       " 0.018166725,\n",
       " -0.0056396853,\n",
       " 0.0072113695,\n",
       " -0.009558363,\n",
       " -0.003384929,\n",
       " 0.0060212337,\n",
       " -0.02846783,\n",
       " -0.032252595,\n",
       " 0.0136137,\n",
       " 0.018993044,\n",
       " 0.039226186,\n",
       " -0.0052503357,\n",
       " 0.014304829,\n",
       " -0.0073776175,\n",
       " -0.013907978,\n",
       " 0.016590707,\n",
       " -0.010951549,\n",
       " -0.013057781,\n",
       " 0.004528226,\n",
       " -0.019255044,\n",
       " -0.015734782,\n",
       " -0.018847547,\n",
       " -0.011201033,\n",
       " -0.037194878,\n",
       " -0.018911919,\n",
       " -0.020856991,\n",
       " 0.010910826,\n",
       " -0.0050990693,\n",
       " 0.03448426,\n",
       " -0.022973023,\n",
       " -0.029288555,\n",
       " 0.02507368,\n",
       " 0.004821676,\n",
       " 0.02025351,\n",
       " -0.04003515,\n",
       " -0.006133195,\n",
       " -0.018465074,\n",
       " -0.020748824,\n",
       " -0.024016416,\n",
       " 0.013240988,\n",
       " 0.021606257,\n",
       " -0.004758037,\n",
       " -0.002478038,\n",
       " 0.0195001,\n",
       " -0.005579835,\n",
       " 0.012023586,\n",
       " 0.03812716,\n",
       " -0.011480934,\n",
       " -0.015237583,\n",
       " 0.024841059,\n",
       " 0.031436246,\n",
       " -0.028731655,\n",
       " -0.04323724,\n",
       " 0.022995336,\n",
       " 0.011046008,\n",
       " -0.004799571,\n",
       " 0.016018054,\n",
       " 0.014350677,\n",
       " 0.004536367,\n",
       " -0.005682214,\n",
       " -0.03152519,\n",
       " -0.012391396,\n",
       " 0.05088486,\n",
       " -0.028851662,\n",
       " -0.0123066325,\n",
       " 0.027168905,\n",
       " -0.016136777,\n",
       " 0.015679302,\n",
       " -0.014802648,\n",
       " -0.013523848,\n",
       " -0.0032730952,\n",
       " -0.015892964,\n",
       " 0.07038323,\n",
       " 0.002030439,\n",
       " -0.028533563,\n",
       " 0.0026184497,\n",
       " -0.031778164,\n",
       " -0.031503484,\n",
       " -0.018472236,\n",
       " -0.036357876,\n",
       " 0.018909506,\n",
       " -0.04944362,\n",
       " 0.019746061,\n",
       " 0.03734775,\n",
       " 0.010656102,\n",
       " 0.018167932,\n",
       " 0.0105194785,\n",
       " 0.012569252,\n",
       " -0.032212645,\n",
       " -0.009330459,\n",
       " -0.008894426,\n",
       " -0.0035275735,\n",
       " 0.03173625,\n",
       " 0.066455096,\n",
       " -0.052593846,\n",
       " 0.008626294,\n",
       " 0.0007970358,\n",
       " 0.018714389,\n",
       " -0.007824688,\n",
       " -0.012137634,\n",
       " 0.018329695,\n",
       " -0.017979749,\n",
       " -0.0115241725,\n",
       " -0.023935534,\n",
       " -0.019488944,\n",
       " 0.005715366,\n",
       " 0.01710641,\n",
       " -0.003787529,\n",
       " 0.020181296,\n",
       " 0.004176902,\n",
       " -0.01490343,\n",
       " 0.023339966,\n",
       " -0.036803514,\n",
       " -0.024875583,\n",
       " 0.02176492,\n",
       " 0.020687165,\n",
       " -0.0028591151,\n",
       " -0.0021573957,\n",
       " -0.0022370145,\n",
       " 0.011884983,\n",
       " -0.030996336,\n",
       " -0.0005842228,\n",
       " 0.019915946,\n",
       " -0.0034001647,\n",
       " -0.019827621,\n",
       " -0.017641786,\n",
       " -0.03268361,\n",
       " -0.017748449,\n",
       " 0.0062322468,\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgBuC-Xdu5gL"
   },
   "source": [
    "### Create and persist Chroma vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ov-ElhBUpJB",
    "outputId": "8fcd703f-120c-46db-ba55-2bc1423c4da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and persisted to './chroma_db'\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding_function = JinaEmbeddings(\n",
    "    jina_api_key=\"\", model_name=\"jina-embeddings-v3\"\n",
    ")\n",
    "collection_name = \"my_collection\"\n",
    "vectorstore = Chroma.from_documents(collection_name=collection_name, documents=splits, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
    "#db.persist()\n",
    "\n",
    "print(\"Vector store created and persisted to './chroma_db'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaRqFWA8u3I8",
    "outputId": "31309e8a-a5b0-4d65-8b36-993e8fc440af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 2 most relevant chunks for the query: 'ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü'\n",
      "\n",
      "Result 1:\n",
      "Source: ./docs/NextView_Technologies_Profile_Urdu.docx\n",
      "Content: ⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\n",
      "ŸÇ€åÿßŸÖ: 2010\n",
      "ŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ\n",
      "\n",
      "Result 2:\n",
      "Source: ./docs/NextView_Technologies_Profile_Urdu.docx\n",
      "Content: ⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\n",
      "ŸÇ€åÿßŸÖ: 2010\n",
      "ŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Perform similarity search\n",
    "\n",
    "query = \"ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\"\n",
    "search_results = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"\\nTop 2 most relevant chunks for the query: '{query}'\\n\")\n",
    "for i, result in enumerate(search_results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"Source: {result.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content: {result.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 2 most relevant chunks for the query: 'Please tell me website of TechNova'\n",
      "\n",
      "Result 1:\n",
      "Source: ./docs/TechNova_Company_Profile.txt\n",
      "Content: Company Name: TechNova Solutions\n",
      "Founded: 2015\n",
      "Headquarters: San Francisco, California, USA\n",
      "\n",
      "Result 2:\n",
      "Source: ./docs/TechNova_Company_Profile.txt\n",
      "Content: Company Name: TechNova Solutions\n",
      "Founded: 2015\n",
      "Headquarters: San Francisco, California, USA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Perform similarity search for second file.\n",
    "\n",
    "query = \"Please tell me website of TechNova\"\n",
    "search_results = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"\\nTop 2 most relevant chunks for the query: '{query}'\\n\")\n",
    "for i, result in enumerate(search_results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"Source: {result.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content: {result.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGkvzzIZvC2R",
    "outputId": "081f1019-f8a3-4dfa-9ed4-22f2d7198cfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\nŸÇ€åÿßŸÖ: 2010\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ'),\n",
       " Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\nŸÇ€åÿßŸÖ: 2010\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retriever.invoke(\"ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XRiNA4y8vkcz"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYCoxqbcvuht",
    "outputId": "aed01866-ba79-4685-cc45-9a060686983d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"Answer the question based only on the following context:\\n[Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\\\nŸÇ€åÿßŸÖ: 2010\\\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ'), Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\\\nŸÇ€åÿßŸÖ: 2010\\\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ')]\\n\\nQuestion: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\\n\\nAnswer: \", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt\n",
    ")\n",
    "rag_chain.invoke(\"ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "uztRXXwDvud9"
   },
   "outputs": [],
   "source": [
    "def docs2str(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kk-VtijcwZw9",
    "outputId": "b976c90d-5d8e-427b-cee7-2281167b746c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Answer the question based only on the following context:\\n⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\nŸÇ€åÿßŸÖ: 2010\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ\\n\\n⁄©ŸÖŸæŸÜ€å ⁄©ÿß ŸÜÿßŸÖ: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤\\nŸÇ€åÿßŸÖ: 2010\\nŸÖÿ±⁄©ÿ≤: ŸÑÿß€ÅŸàÿ±ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ\\n\\nQuestion: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\\n\\nAnswer: ', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | docs2str, \"question\": RunnablePassthrough()} | prompt\n",
    ")\n",
    "rag_chain.invoke(\"ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gjDAr3lwbXA",
    "outputId": "7a9df563-e772-401a-be4f-7abecb58ce40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | docs2str, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "question = \"ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RPDMn9q4GbE"
   },
   "source": [
    "### Conversational RAG\n",
    "\n",
    "#### Handling Follow Up Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hbbjrk1cwl19"
   },
   "outputs": [],
   "source": [
    "# Example conversation\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "chat_history = []\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=question),\n",
    "    AIMessage(content=response)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApN5nctt2XSn",
    "outputId": "61d19ef0-2efb-44df-f098-1754cb19be2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='2010', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Sm2ju8n72YXY",
    "outputId": "eebba764-fee0-412a-dafc-528d5cb49d6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€í ŸÑÿ¶€í ⁄©⁄Ü⁄æ ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ÿå ŸÖÿ´ŸÑÿßŸã:\\n\\n1. ŸÖŸàÿßÿµŸÑÿßÿ™ ⁄©€å Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà ŸÖŸàÿ®ÿßÿ¶ŸÑ ŸÖŸàÿßÿµŸÑÿßÿ™ ⁄©€å Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ÿ¨€åÿ≥€í 5Gÿå ŸÜÿß€åÿßÿ® ŸÖŸàÿßÿØ ⁄©€å ŸÖŸàÿßÿµŸÑÿßÿ™ÿå ÿßŸàÿ± ŸÖŸàÿßÿµŸÑÿßÿ™ ⁄©€å ÿ≥€å⁄©€åŸàÿ±Ÿπ€å ⁄©€í ŸÑÿ¶€í ÿ™ÿ≠ŸÇ€åŸÇ ÿßŸàÿ± ÿ™ÿ±ŸÇ€å ⁄©ÿ±ÿ™€å €Å€í€î\\n2. ⁄à€åŸπÿß ÿ≥€åŸÜŸπÿ±: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà ⁄©€í ⁄à€åŸπÿß ÿ≥€åŸÜŸπÿ±ÿ≤ ⁄à€åŸπÿß ⁄©Ÿà ŸÖÿ≠ŸÅŸàÿ∏ÿå ÿ≥€å⁄©€åŸàÿ±ÿå ÿßŸàÿ± ÿß€å⁄©ÿ≥ÿ±Ÿπ ⁄©ÿ±ÿ™€í €Å€å⁄∫€î\\n3. ÿ®ÿ±ÿß⁄àÿ®€åŸÜ⁄à ÿÆÿØŸÖÿßÿ™: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà ÿ®ÿ±ÿß⁄àÿ®€åŸÜ⁄à ÿÆÿØŸÖÿßÿ™ ÿ¨€åÿ≥€í ÿßŸÜŸπÿ±ŸÜ€åŸπÿå Ÿπ€å Ÿà€åÿå ÿßŸàÿ± ŸÅÿßÿ¶ÿ®ÿ± ÿßŸæŸπ⁄© ⁄©€å ÿ™ÿ±ŸÇ€å ÿßŸàÿ± ÿßŸæ ⁄Øÿ±€å⁄à€åÿ¥ŸÜ ⁄©€í ŸÑÿ¶€í ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€å €Å€í€î\\n4. ÿßŸÜŸπÿ±ŸÜ€åŸπ ÿ¢ŸÅ ÿ™⁄æŸÜ⁄Øÿ≤: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà ÿßŸÜŸπÿ±ŸÜ€åŸπ ÿ¢ŸÅ ÿ™⁄æŸÜ⁄Øÿ≤ (IoT) ⁄©€å Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ÿå ⁄à€åŸàÿßÿ¶ÿ≥ÿ≤ÿå ÿßŸàÿ± ÿ≥ŸàŸÑŸàÿ¥ŸÜÿ≤ ⁄©€í ŸÑÿ¶€í ÿ™ÿ≠ŸÇ€åŸÇ ÿßŸàÿ± ÿ™ÿ±ŸÇ€å ⁄©ÿ±ÿ™€å €Å€í€î'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# history_aware_retriever = create_history_aware_retriever(\n",
    "#     llm, retriever, contextualize_q_prompt\n",
    "# )\n",
    "contextualize_chain = contextualize_q_prompt | llm | StrOutputParser()\n",
    "contextualize_chain.invoke({\"input\": \"ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vShrBX-M24_r",
    "outputId": "77755e1c-890c-49e8-deb0-daa9de3ae6fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='€ÅŸÖÿßÿ±€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫:\\nŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€å €Å€í ÿ¨Ÿà ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î \\n€ÅŸÖÿßÿ±€å Ÿπ€åŸÖ ⁄©ÿß ŸÖŸÇÿµÿØ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß €Å€í€î'),\n",
       " Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='€ÅŸÖÿßÿ±€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫:\\nŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€å €Å€í ÿ¨Ÿà ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î \\n€ÅŸÖÿßÿ±€å Ÿπ€åŸÖ ⁄©ÿß ŸÖŸÇÿµÿØ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß €Å€í€î')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "history_aware_retriever.invoke({\"input\": \"ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0BMwLBo7jhV",
    "outputId": "801db6d2-0cf6-448d-81ae-bfd90ce9d479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™:\\n1. Ÿà€åÿ® ÿßŸàÿ± ŸÖŸàÿ®ÿßÿ¶ŸÑ ÿß€åŸæŸÑ€å⁄©€åÿ¥ŸÜ ⁄àŸà€åŸÑŸæŸÖŸÜŸπ\\n2. ⁄à€åÿ¨€åŸπŸÑ ŸÖÿßÿ±⁄©€åŸπŸÜ⁄Ø ÿßŸàÿ± ÿ®ÿ±ÿßŸÜ⁄àŸÜ⁄Ø\\n3. ÿß€å ⁄©ÿßŸÖÿ±ÿ≥ ÿ≥ŸÑŸàÿ¥ŸÜÿ≤\\n4. ⁄©ŸÑÿßÿ§⁄à ÿ®€åÿ≥⁄à ÿß€åŸæŸÑ€å⁄©€åÿ¥ŸÜÿ≤\\n5. ÿ¢ÿ±Ÿπ€åŸÅ€åÿ¥ŸÑ ÿßŸÜŸπ€åŸÑ€åÿ¨ŸÜÿ≥ Ÿæÿ± ŸÖÿ®ŸÜ€å Ÿæÿ±ÿß⁄à⁄©Ÿπÿ≥'),\n",
       " Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™:\\n1. Ÿà€åÿ® ÿßŸàÿ± ŸÖŸàÿ®ÿßÿ¶ŸÑ ÿß€åŸæŸÑ€å⁄©€åÿ¥ŸÜ ⁄àŸà€åŸÑŸæŸÖŸÜŸπ\\n2. ⁄à€åÿ¨€åŸπŸÑ ŸÖÿßÿ±⁄©€åŸπŸÜ⁄Ø ÿßŸàÿ± ÿ®ÿ±ÿßŸÜ⁄àŸÜ⁄Ø\\n3. ÿß€å ⁄©ÿßŸÖÿ±ÿ≥ ÿ≥ŸÑŸàÿ¥ŸÜÿ≤\\n4. ⁄©ŸÑÿßÿ§⁄à ÿ®€åÿ≥⁄à ÿß€åŸæŸÑ€å⁄©€åÿ¥ŸÜÿ≤\\n5. ÿ¢ÿ±Ÿπ€åŸÅ€åÿ¥ŸÑ ÿßŸÜŸπ€åŸÑ€åÿ¨ŸÜÿ≥ Ÿæÿ± ŸÖÿ®ŸÜ€å Ÿæÿ±ÿß⁄à⁄©Ÿπÿ≥')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-AYJ1jce6cbQ"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Use the following context to answer the user's question.\"),\n",
    "    #  (\"system\", \"Tell me joke on Programming\"),\n",
    "    (\"system\", \"Context: {context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkeEE0hD65zW",
    "outputId": "accc91c8-5db0-418f-fdec-114ae6f7f47c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü',\n",
       " 'chat_history': [HumanMessage(content='ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2010', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='€ÅŸÖÿßÿ±€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫:\\nŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€å €Å€í ÿ¨Ÿà ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î \\n€ÅŸÖÿßÿ±€å Ÿπ€åŸÖ ⁄©ÿß ŸÖŸÇÿµÿØ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß €Å€í€î'),\n",
       "  Document(metadata={'source': './docs/NextView_Technologies_Profile_Urdu.docx'}, page_content='€ÅŸÖÿßÿ±€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫:\\nŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€å €Å€í ÿ¨Ÿà ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î \\n€ÅŸÖÿßÿ±€å Ÿπ€åŸÖ ⁄©ÿß ŸÖŸÇÿµÿØ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß €Å€í€î')],\n",
       " 'answer': 'ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€í ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ŸÖ€å⁄∫ ÿ¨ÿØ€åÿØ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ÿßŸàÿ± ⁄à€åÿ¨€åŸπŸÑ ÿ≠ŸÑ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜÿß ÿ¥ÿßŸÖŸÑ €Å€í€î ÿßŸÜ€ÅŸà⁄∫ ŸÜ€í ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ŸÜ€í ⁄©ÿß ŸÖŸÇÿµÿØ ÿ±⁄©⁄æÿß €Å€í€î'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\": \"ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü\", \"chat_history\":chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qdzx68u5aCv"
   },
   "source": [
    "### Building Multi User Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ftIORKEF3coG"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "DB_NAME = \"rag_app.db\"\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    return conn\n",
    "\n",
    "def create_application_logs():\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
    "                    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                     session_id TEXT,\n",
    "                     user_query TEXT,\n",
    "                     gpt_response TEXT,\n",
    "                     model TEXT,\n",
    "                     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
    "    conn.close()\n",
    "\n",
    "def insert_application_logs(session_id, user_query, gpt_response, model):\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('INSERT INTO application_logs (session_id, user_query, gpt_response, model) VALUES (?, ?, ?, ?)',\n",
    "                 (session_id, user_query, gpt_response, model))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT user_query, gpt_response FROM application_logs WHERE session_id = ? ORDER BY created_at', (session_id,))\n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.extend([\n",
    "            {\"role\": \"human\", \"content\": row['user_query']},\n",
    "            {\"role\": \"ai\", \"content\": row['gpt_response']}\n",
    "        ])\n",
    "    conn.close()\n",
    "    return messages\n",
    "\n",
    "# Initialize the database\n",
    "create_application_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M--sjKYN6JIQ",
    "outputId": "1461b818-15d8-4f67-c6ac-4a10b0f7a5d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Human: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\n",
      "AI: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ 2010 ŸÖ€å⁄∫ ÿ±⁄©⁄æ€å ⁄Øÿ¶€å ÿ™⁄æ€å€î\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "session_id = str(uuid.uuid4())\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "question1 = \"ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü\"\n",
    "answer1 = rag_chain.invoke({\"input\": question1, \"chat_history\":chat_history})['answer']\n",
    "insert_application_logs(session_id, question1, answer1, \"meta-llama/Llama-Vision-Free\")\n",
    "print(f\"Human: {question1}\")\n",
    "print(f\"AI: {answer1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqDRm5Rl6P5U",
    "outputId": "39944daf-182e-4148-85dd-83ac766e637e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'human', 'content': 'ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ ⁄©ÿ® ÿ±⁄©⁄æ€å ⁄Øÿ¶€åÿü'}, {'role': 'ai', 'content': 'ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿ®ŸÜ€åÿßÿØ 2010 ŸÖ€å⁄∫ ÿ±⁄©⁄æ€å ⁄Øÿ¶€å ÿ™⁄æ€å€î'}]\n",
      "Human: ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü\n",
      "AI: ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ÿå Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ⁄©€å ÿß€å⁄© ŸÖÿπÿ±ŸàŸÅ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å ⁄©ŸÖŸæŸÜ€åÿå ŸÖÿÆÿ™ŸÑŸÅ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ⁄à€åÿ¨€åŸπŸÑ ÿØŸàÿ± ŸÖ€å⁄∫ ÿ™ÿ±ŸÇ€å ÿØ€åŸÜ€í ⁄©€í ŸÑ€å€í ÿ™ÿÆŸÑ€åŸÇ€å ÿßŸàÿ± ÿ¨ÿØ€åÿØ Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€å Ÿæÿ± ŸÖÿ®ŸÜ€å ÿÆÿØŸÖÿßÿ™ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€í€î\n",
      "\n",
      "ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ŸÖ€å⁄∫ ÿ¥ÿßŸÖŸÑ €Å€å⁄∫:\n",
      "\n",
      "1- ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ± ⁄àŸà€åŸÑŸæŸÖŸÜŸπ\n",
      "\n",
      "2- ⁄à€åÿ¨€åŸπŸÑ ŸÖÿßÿ±⁄©€åŸπŸÜ⁄Ø ÿßŸàÿ± ÿß€å ŸÖ€åŸÑ ŸÖÿßÿ±⁄©€åŸπŸÜ⁄Ø\n",
      "\n",
      "3- ⁄à€åŸπÿß ÿß€åŸÜÿßŸÑÿßÿ¶Ÿπ⁄©ÿ≥ ÿßŸàÿ± Ÿà€å⁄òŸÜ\n",
      "\n",
      "4- ÿß€åŸÜ⁄àŸÑÿ≥ ÿ≥ÿßŸÅŸπ Ÿà€åÿ¶ÿ±\n",
      "\n",
      "5- ⁄à€åÿ¨€åŸπŸÑ transformed ÿ≥ŸàŸÑŸàÿ¥ŸÜÿ≤\n",
      "\n",
      "ŸÜ€å⁄©ÿ≥Ÿπ Ÿà€åŸà Ÿπ€å⁄©ŸÜÿßŸÑŸàÿ¨€åÿ≤ ⁄©€å ÿÆÿØŸÖÿßÿ™ ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±Ÿà⁄∫ ⁄©Ÿà ÿßŸÜ ⁄©€í ⁄à€åÿ¨€åŸπŸÑ ⁄Øÿ±ŸàŸæ ⁄©€å ÿ™ÿ±ŸÇ€å ŸÖ€å⁄∫ ŸÖÿØÿØ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±ÿ™€å €Å€å⁄∫ ÿ™ÿß⁄©€Å Ÿà€Å ÿ≤€åÿßÿØ€Å ŸÖÿ§ÿ´ÿ± ÿ∑ÿ±€åŸÇ€í ÿ≥€í ÿßŸæŸÜ€í ÿ™.Œ£ŸÑ⁄©Ÿπÿ± ⁄©Ÿà ÿ≥ŸÖÿ¨⁄æ€å⁄∫ ÿßŸàÿ± ⁄ÜŸÑÿßÿ¶€å⁄∫€î\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question2 = \"ÿßÿ≥ ⁄©€å ÿß€ÅŸÖ ÿÆÿØŸÖÿßÿ™ ⁄©€åÿß €Å€å⁄∫ÿü\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "answer2 = rag_chain.invoke({\"input\": question2, \"chat_history\":chat_history})['answer']\n",
    "insert_application_logs(session_id, question2, answer2, \"meta-llama/Llama-Vision-Free\")\n",
    "print(f\"Human: {question2}\")\n",
    "print(f\"AI: {answer2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgQiUzN68KYl"
   },
   "source": [
    "New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jWmJ0FgD78AO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Human: What is TechNova\n",
      "AI: TechNova Solutions is a technology company founded in 2015, with its headquarters located in San Francisco, California, USA. Unfortunately, I don't have any specific information about the company's products or services, but it appears to be a relatively new player in the tech industry.\n",
      "\n",
      "If you're looking for more information about TechNova Solutions, I suggest checking their official website or social media channels to learn more about their mission, products, and services.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_id = str(uuid.uuid4())\n",
    "question = \"What is TechNova\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "answer = rag_chain.invoke({\"input\": question, \"chat_history\":chat_history})['answer']\n",
    "insert_application_logs(session_id, question, answer, \"meta-llama/Llama-Vision-Free\")\n",
    "print(f\"Human: {question}\")\n",
    "print(f\"AI: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ssvjqblJ8SC3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'human', 'content': 'What is TechNova'}, {'role': 'ai', 'content': \"TechNova Solutions is a technology company founded in 2015, with its headquarters located in San Francisco, California, USA. Unfortunately, I don't have any specific information about the company's products or services, but it appears to be a relatively new player in the tech industry.\\n\\nIf you're looking for more information about TechNova Solutions, I suggest checking their official website or social media channels to learn more about their mission, products, and services.\"}, {'role': 'human', 'content': 'Plese tell me its officail website'}, {'role': 'ai', 'content': 'I made an error earlier. After conducting a search, I was unable to find a website or any online presence for a company called \"TechNova Solutions\" with headquarters in San Francisco, California.\\n\\nIt\\'s possible that the company may not have a publicly available website or may be a private organization. If you have any more information about TechNova Solutions, I may be able to help you better.'}]\n",
      "Human: Plese tell me its officail website\n",
      "AI: I couldn't find any official website for TechNova Solutions. I made an error earlier in my previous responses. It seems that TechNova Solutions may not have a publicly available website. If you need to contact the company, I suggest trying a search engine or a business directory to see if you can find any other information about them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question2 = \"Plese tell me its officail website\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "answer2 = rag_chain.invoke({\"input\": question2, \"chat_history\":chat_history})['answer']\n",
    "insert_application_logs(session_id, question2, answer2, \"meta-llama/Llama-Vision-Free\")\n",
    "print(f\"Human: {question2}\")\n",
    "print(f\"AI: {answer2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
